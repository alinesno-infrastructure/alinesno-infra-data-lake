# 执行脚本示例 

```python
from pyspark.sql import SparkSession

spark = (
    SparkSession.builder
    .appName("IcebergOnOSS")
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") 
    .config("spark.sql.catalog.aip_catalog", "org.apache.iceberg.spark.SparkCatalog")  
    .config("spark.sql.catalog.aip_catalog.catalog-impl", "org.apache.iceberg.jdbc.JdbcCatalog") 
    .config("spark.sql.catalog.aip_catalog.uri", "jdbc:mysql://localhost:3306/dev_alinesno_infra_data_lake_v100?zeroDateTimeBehavior=CONVERT_TO_NULL")  
    .config("spark.sql.catalog.aip_catalog.warehouse", "oss://alinesno-datalake/") 
    .config("spark.sql.catalog.aip_catalog.skip-version-hint", "true") 
    .config("spark.hadoop.fs.oss.impl", "org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem")
    .config("spark.hadoop.fs.oss.endpoint", "oss-cn-hangzhou.aliyuncs.com") 
    .getOrCreate()
)

# 创建数据库（如果不存在）
spark.sql("CREATE DATABASE IF NOT EXISTS aip_catalog.test_db2223")

# 创建表
create_table_sql = """
CREATE TABLE IF NOT EXISTS aip_catalog.test_db222.my_table233 (
    id BIGINT,
    name STRING,
    age INT,
    email STRING,
    created_date DATE,
    salary DECIMAL(10,2)
) USING iceberg
PARTITIONED BY (created_date)
"""
spark.sql(create_table_sql)

print("表创建成功！")
```